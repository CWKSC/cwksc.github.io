---
title: Explain ZH
---

## 詳細解釋

本題的目標是執行 **貝葉斯線性迴歸 (Bayesian Linear Regression)**。與標準的最大似然估計（導致最小二乘法）不同，在貝葉斯方法中，我們將參數 $\theta$ 視為具有 **先驗分佈 (Prior distribution)** 的隨機變數。

### 1. 模型與先驗

*   **似然 (Likelihood)**: 輸入與輸出之間的關係是線性的（在特徵空間中），並加上了高斯雜訊。這意味著如果我們知道 $\theta$，觀察到 $y$ 的機率服從以預測值 $\Phi^T \theta$ 為中心的高斯分佈。
*   **先驗 (Prior)**: 在看到任何數據之前，我們假設 $\theta$ 服從以 0 為中心，共變異數為 $\Gamma$ 的高斯分佈。這編碼了我們的信念，即權重不應過大（正則化）。

### 2. 推導後驗

我們想找出 $p(\theta | \mathcal{D})$，這代表了在看到數據後我們對參數的更新信念。我們使用貝葉斯法則：

$$
\text{後驗 (Posterior)} \propto \text{似然 (Likelihood)} \times \text{先驗 (Prior)}
$$

由於似然和先驗都是高斯分佈，後驗也將是高斯分佈。這是共軛分佈（高斯分佈對於平均值是自我共軛的）的特性。

推導主要涉及指數函數內的線性代數運算：

1.  **指數**: 我們將先驗和似然的指數函數相乘。根據對數規則 ($\exp(A)\exp(B) = \exp(A+B)$)，這對應於將指數內的參數相加。
2.  **二次型 (Quadratic Form)**: 多元高斯指數的參數是一個二次型：$-\frac{1}{2}(\theta - \mu)^T \Sigma^{-1} (\theta - \mu)$。
3.  **配方 (Completing the Square)**: 我們展開先驗和似然參數的總和，並將所有包含 $\theta$ 的項分組。
    *   隨 $\theta^T \dots \theta$ 縮放的項（二次項）決定了 **精確度矩陣 (Precision Matrix)**（逆變異數）。我們發現後驗精確度是先驗精確度 ($\Gamma^{-1}$) 和數據精確度 ($\Phi \Sigma^{-1} \Phi^T$) 的總和。
    *   $\theta$ 的線性項幫助我們找到 **後驗平均值 (Posterior Mean)**。
4.  **結果**:
    *   **後驗共變異數 ($\hat{\Sigma}_\theta$)**: 隨著我們獲得更多數據，它會收縮（$\Phi \Sigma^{-1} \Phi^T$ 項增長，逆矩陣變小）。
    *   **後驗平均值 ($\hat{\mu}_\theta$)**: 它是先驗平均值 (0) 和數據估計值的加權組合。

這個結果是貝葉斯學習的基礎。它展示了數據如何更新我們對模型參數的不確定性 ($\Sigma$) 和最佳猜測 ($\mu$)。
