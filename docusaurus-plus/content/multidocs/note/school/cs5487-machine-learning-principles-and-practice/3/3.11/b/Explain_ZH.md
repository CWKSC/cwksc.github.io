---
title: Explain ZH
---

## 詳細解釋

MAP 估計是最大化後驗機率的 $\theta$ 值。根據假設的不同，它與其他迴歸方法有關：

### 1. 公式
推導出的 MAP 估計為：
$$
\hat{\theta}_{MAP} = (\underbrace{\Gamma^{-1}}_{\text{先驗 (Prior)}} + \underbrace{\Phi \Sigma^{-1} \Phi^T}_{\text{數據 (Data)}})^{-1} \underbrace{\Phi \Sigma^{-1} y}_{\text{數據 (Data)}}
$$

### 2. 與最小二乘法的關聯
*   **普通最小二乘法 (OLS)**: 最小化平方誤差項。它假設每個數據點都同等重要，且沒有先驗信念。
*   **加權最小二乘法 (WLS)**: 最小化 *加權* 平方誤差。它使用 $\Sigma^{-1}$ 給予雜訊較大的觀測值較小的權重。它對應於非獨立同分佈 (non-i.i.d.) 雜訊的最大似然估計。

MAP 估計看起來像 WLS，但在矩陣求逆中增加了一個額外的項：$\Gamma^{-1}$。

### 3. $\Gamma^{-1}$ 的作用（正則化）
$\Gamma^{-1}$ 項是先驗共變異數的逆矩陣。它量化了我們在看到數據之前對 $\theta$ 接近 0 的「確定程度」。
*   如果 $\Gamma$ 的元素很大（變異數大），$\Gamma^{-1}$ 很小。先驗很弱，MAP $\approx$ ML。
*   如果 $\Gamma$ 的元素很小（變異數小），$\Gamma^{-1}$ 很大。先驗很強，MAP 會被強力拉向 0（或先驗平均值）。

### 4. 優勢
貝葉斯/MAP 方法（非零 $\Gamma^{-1}$）的主要優勢是處理病態問題 (ill-posed problems)：
*   **可逆性**: 在標準迴歸中，如果你有 10 個數據點和 100 個特徵，$\Phi \Phi^T$ 是不可逆的。你無法找到唯一解。通過加上 $\Gamma^{-1}$（如 Ridge Regression 中的 $\lambda I$），矩陣變得可逆，並且存在唯一解。
*   **過度擬合**: 標準 LS 試圖完美擬合訓練雜訊。MAP 懲罰複雜模型（大權重），從而在未見數據上具有更好的泛化能力。
