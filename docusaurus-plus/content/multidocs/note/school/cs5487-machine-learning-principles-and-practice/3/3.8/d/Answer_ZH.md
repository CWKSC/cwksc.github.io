---
title: Answer ZH
---

# 問題 3.8(d) 答案

## 1. 最大似然估計 (ML)

ML 估計最大化似然函數 $p(\mathcal{D}|\pi) = \pi^s (1-\pi)^{n-s}$。
為了找到最大值，我們取對數似然並求導：
$$L(\pi) = s \ln \pi + (n-s) \ln (1-\pi)$$
$$\frac{\partial L}{\partial \pi} = \frac{s}{\pi} - \frac{n-s}{1-\pi} = 0$$
$$s(1-\pi) = (n-s)\pi \implies s - s\pi = n\pi - s\pi \implies s = n\pi$$
$$
\hat{\pi}_{ML} = \frac{s}{n}
$$

## 2. MAP 估計 (均勻先驗)

MAP (最大後驗概率) 估計最大化後驗 $p(\pi|\mathcal{D}) \propto p(\mathcal{D}|\pi)p(\pi)$。
對於均勻先驗，$p(\pi) = 1$。
所以我們最大化 $p(\mathcal{D}|\pi) \cdot 1$。
這與似然函數完全相同。
因此，對於均勻先驗：
$$
\hat{\pi}_{MAP} = \hat{\pi}_{ML} = \frac{s}{n}
$$

## 3. 比較和優勢 (貝葉斯均值 vs MAP/ML)

等等，上一節 (c) 推導了 **貝葉斯均值** 估計 $\frac{s+1}{n+2}$。問題要求比較估計值。通常，“估計值”指的是點估計。
然而，在這個特定背景下（均勻先驗），MAP 和 ML 是相同的 ($\frac{s}{n}$)。另一個合乎邏輯的比較對象是 (c) 中計算的 **後驗均值**（期望值），即 $\frac{s+1}{n+2}$。

**後驗均值 (貝葉斯估計) 相對於 ML/MAP 的優勢：**
* **平滑**：如果 $s=0$ 或 $s=n$，ML/MAP 估計可以是 0 或 1。這通常是過擬合，特別是對於小樣本量。它將 0 概率分配給未見過的事件。
* 貝葉斯均值 $\frac{s+1}{n+2}$ 總是嚴格在 0 和 1 之間，避免了對未見數據的無限對數損失（零頻率問題）。

**與均勻先驗的關係：**
MAP 等於 ML 這一事實是均勻先驗為常數的直接結果。常數先驗在眾數計算中不會將估計值拉向任何特定值。
然而，均勻先驗 *確實* 影響均值。如 (c) 所示，均勻先驗添加了“虛擬樣本”（1 次成功，1 次失敗）。這將均值“拉”向 $0.5$。

* 如果 $s/n = 0.5$，則 $\frac{s+1}{n+2} = 0.5$。（無差異）。
* 如果 $s/n = 1$，則 $\frac{n+1}{n+2} < 1$。（貝葉斯估計更保守）。
