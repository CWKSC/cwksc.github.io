---
title: Explain ZH
---

## 解說

理想情況下，我們會希望獨立地為每個 $\pi_j$ 最大化 $\sum N_j \log \pi_j$。然而，我們有一個 **約束條件**。我們正在建模機率，因此所有 $\pi_j$ 的總和必須正好為 1。如果我們只是單純增加某個 $\pi_j$ 來最大化對數似然值而不考慮懲罰，我們可能會打破這個規則（例如，它們的總和可能會超過 1）。

**拉格朗日乘數 (Lagrange Multiplier)** 方法引入了一個新變數 $\lambda$ (lambda) 來強制執行這個「總和為 1」的規則。

1. **回顧公式**：多項分佈 (multinomial distribution) 的對數機率包含 $\sum N_j \log \pi_j$ 這樣的項。
2. **梯度 (Gradient)**：我們想要沿著這個函數的斜率（梯度）找到頂點（最大值）。
3. **平衡力**：$\lambda (\sum \pi_j - 1)$ 這一項充當平衡力。
    * 當我們對 $\pi_j$ 取導數時，得到 $N_j/\pi_j + \lambda = 0$。
    * 這意味著 $\pi_j$ 與 $N_j$ 成正比（具體來說 $\pi_j = -N_j / \lambda$）。
4. **歸一化 (Normalization)**：由於所有 $\pi_j$ 的總和必須為 1，且每個 $\pi_j$ 都與 $N_j$ 成正比，因此比例常數必須確保總和為 1。
    * 部分之和 = $N_j$ 的總和。
    * 因此，每個部分 $\pi_j$ 僅僅是該類別被觀察到的次數 ($N_j$) 除以總觀察次數 ($\sum N_k$)。

這個結果非常直觀：類別機率的極大似然估計 (MLE) 僅僅是該類別被觀察到的比例（即 $N_j$ 除以總數 $\sum N_k$）。
