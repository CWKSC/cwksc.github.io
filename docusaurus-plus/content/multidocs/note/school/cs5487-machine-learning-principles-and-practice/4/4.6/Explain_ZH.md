---
title: Explain ZH
---

## 指數混合模型 EM 推導詳解

期望最大化 (EM) 演算法是在具有隱變量 (Hidden Variables) 的模型中尋找最大概似估計的標準工具。在混合模型中，「隱」變量是指生成每個數據點的分量 ID。我們不知道哪個指數分佈生成了哪個 $x_i$，所以我們必須以機率的方式進行估計。

### 1. E 步驟：猜測標籤

「期望」步驟 (E-step) 基本上是在問：**「給定我們目前的參數估計 $(\pi, \lambda)$，數據點 $x_i$ 來自其分量 $j$ 的可能性有多大？」**

這個機率被稱為 **責任值 (Responsibility)**，記為 $\gamma_{ij}$。
* 分子 $\pi_j p(x_i|\lambda_j)$ 是「選中分量 $j$ 且觀察到 $x_i$」的聯合機率。
* 分母是「觀察到 $x_i$」的總機率（所有可能分量的總和，即全機率公式）。
* 結果是一個歸一化的機率（對於每個 $i$，對所有 $j$ 求和為 1）。

### 2. M 步驟：更新參數

「最大化」步驟 (M-step) 是在問：**「給定我們先前對標籤的軟猜測 ($\gamma_{ij}$)，最佳的參數是什麼？」**

我們最大化 **Q 函數**，即期望對數概似函數。這有效地將問題分開，使我們可以將每個分量視為獨立的問題來處理，並以責任值作為權重。

#### 更新 $\pi_j$ (混合係數)

$\pi_j$ 的更新直觀上就是分配機率的統計平均值。
$$
\pi_j = \frac{1}{n} \sum_{i=1}^n \gamma_{ij}
$$
這意味著：「分量 $j$ 的機率是該分量對所有數據點平均承擔的責任。」如果分量 1 對每個點都承擔了 30% 的責任，那麼 $\pi_1$ 就應該是 0.3。

#### 更新 $\lambda_j$ (速率參數)

對於標準的指數分佈，$\lambda$ 的 MLE 是 $1 / \text{平均值}(x)$。
$$
\lambda_{MLE} = \frac{n}{\sum x_i}
$$
在混合情況下，我們有一個 **加權** 版本。
* 分子 $\sum_{i=1}^n \gamma_{ij}$ 是分配給分量 $j$ 的「有效點數」（通常記為 $N_j$）。
* 分母 $\sum_{i=1}^n \gamma_{ij} x_i$ 是分配給分量 $j$ 的「數值加權和」。

所以更新公式實際上是：
$$
\lambda_j = \frac{1}{\text{分量 } j \text{ 的加權平均 } x} = \frac{N_j}{\sum_{i=1}^n \gamma_{ij} x_i}
$$
這與單一指數分佈的直觀概念一致，但根據每個點屬於該分量的程度進行了加權。
