---
title: Explain ZH
---

## 直觀解釋

結果 $\hat{\Sigma} = S_{\text{sample}} + H$ 告訴了我們關於平滑化的一個基本事實：

**平滑化總是會增加變異數。**

將資料點想像成尖銳的釘子（寬度為零，圍繞該點的變異數為零）。樣本共變異數 $S$ 測量這些釘子距離中心的程度。
當我們用寬度為 $H$ 的核函數替換每個釘子時，我們本質上是向每個資料點添加隨機雜訊。這就像是將一個隨機變數 $\epsilon \sim \mathcal{N}(0, H)$ 加到每個樣本 $x_i$ 上。

獨立變數和的變異數等於它們變異數的和：
$\text{Var}(X + \epsilon) = \text{Var}(X) + \text{Var}(\epsilon) = S + H$。

**與偏差 (Bias) 的關係：**
這種變異數的膨脹是一種系統性誤差（偏差）。
* **真實變異數**：$\Sigma$
* **估計變異數**：$\Sigma + H$

估計量系統性地*高估*了分佈的分散程度。這是我們為了讓分佈變得平滑所付出的代價。如果我們想要一條非常平滑的曲線（大 $H$），我們必須接受我們估計的分佈會比真實分佈寬得多（變異數偏差較大）。這說明了 KDE 中的**偏差-變異數權衡 (bias-variance tradeoff)**：較大的頻寬減少了密度估計*量*的變異（曲線不會隨不同的樣本而改變太多），但增加了密度估計*值*的偏差（曲線過於簡單/寬）。
